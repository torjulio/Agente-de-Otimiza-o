# ü§ñ Agente de Otimiza√ß√£o de C√≥digo Python

> Um sistema inteligente e escal√°vel para an√°lise e otimiza√ß√£o de c√≥digo Python, desenvolvido com FastAPI, PostgreSQL e integra√ß√£o Crew AI.

## üìã √çndice

- [Vis√£o Geral](#-vis√£o-geral)
- [Caracter√≠sticas Principais](#-caracter√≠sticas-principais)
- [Arquitetura do Sistema](#-arquitetura-do-sistema)
- [Instala√ß√£o e Configura√ß√£o](#-instala√ß√£o-e-configura√ß√£o)
- [Como Usar](#-como-usar)
- [API Endpoints](#-api-endpoints)
- [Integra√ß√£o Crew AI](#-integra√ß√£o-crew-ai)
- [Escalabilidade](#-escalabilidade)
- [Monitoramento](#-monitoramento)
- [Desenvolvimento](#-desenvolvimento)
- [Testes](#-testes)
- [Contribui√ß√£o](#-contribui√ß√£o)
- [Licen√ßa](#-licen√ßa)

## üéØ Vis√£o Geral

O **Agente de Otimiza√ß√£o de C√≥digo Python** √© uma solu√ß√£o completa e inteligente projetada para analisar c√≥digo Python e fornecer sugest√µes detalhadas de otimiza√ß√£o baseadas em boas pr√°ticas, performance, seguran√ßa e manutenibilidade.

### Por que este projeto existe?

Desenvolver c√≥digo de qualidade √© um desafio constante. Este agente foi criado para:

- **Automatizar a revis√£o de c√≥digo**: Identifica problemas comuns e oportunidades de melhoria
- **Educar desenvolvedores**: Fornece explica√ß√µes detalhadas sobre cada sugest√£o
- **Melhorar a qualidade**: Ajuda a manter padr√µes consistentes em projetos
- **Economizar tempo**: Reduz o tempo gasto em revis√µes manuais de c√≥digo

### O que torna este projeto especial?

1. **An√°lise Inteligente**: Utiliza AST (Abstract Syntax Tree) para an√°lise profunda do c√≥digo
2. **Orquestra√ß√£o Avan√ßada**: Integra√ß√£o com Crew AI para workflows complexos
3. **Escalabilidade**: Arquitetura preparada para crescimento e alta demanda
4. **Monitoramento Completo**: Sistema de observabilidade integrado
5. **Interface Amig√°vel**: API REST bem documentada e f√°cil de usar

## ‚ú® Caracter√≠sticas Principais

### üîç An√°lise Abrangente
- **Performance**: Identifica gargalos e oportunidades de otimiza√ß√£o
- **Legibilidade**: Sugere melhorias na clareza e organiza√ß√£o do c√≥digo
- **Boas Pr√°ticas**: Verifica conformidade com PEP 8 e padr√µes Python
- **Seguran√ßa**: Detecta vulnerabilidades e pr√°ticas inseguras
- **Manutenibilidade**: Avalia complexidade e sugere refatora√ß√µes

### üöÄ Tecnologias Modernas
- **FastAPI**: Framework web moderno e perform√°tico
- **PostgreSQL**: Banco de dados robusto para persist√™ncia
- **Redis**: Cache distribu√≠do para alta performance
- **Crew AI**: Orquestra√ß√£o inteligente de agentes
- **Docker**: Containeriza√ß√£o para deploy simplificado

### üìä Monitoramento e Observabilidade
- **M√©tricas em Tempo Real**: Acompanhamento de performance e uso
- **Alertas Inteligentes**: Notifica√ß√µes autom√°ticas de problemas
- **Dashboards**: Visualiza√ß√£o clara do status do sistema
- **Logs Estruturados**: Rastreabilidade completa de opera√ß√µes

### üîß Escalabilidade
- **Arquitetura Horizontal**: Suporte a m√∫ltiplas inst√¢ncias
- **Cache Inteligente**: Otimiza√ß√£o autom√°tica de performance
- **Processamento Ass√≠ncrono**: Filas para an√°lises pesadas
- **Load Balancing**: Distribui√ß√£o eficiente de carga

## üèóÔ∏è Arquitetura do Sistema

O sistema foi projetado com uma arquitetura modular e escal√°vel:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   API Gateway   ‚îÇ    ‚îÇ   Load Balancer ‚îÇ    ‚îÇ   Monitoring    ‚îÇ
‚îÇ   (FastAPI)     ‚îÇ    ‚îÇ    (Nginx)      ‚îÇ    ‚îÇ  (Prometheus)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                       ‚îÇ                       ‚îÇ
         ‚ñº                       ‚ñº                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Agente Core    ‚îÇ    ‚îÇ  Cache Layer    ‚îÇ    ‚îÇ  Message Queue  ‚îÇ
‚îÇ  (Analisador)   ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ    (Redis)      ‚îÇ    ‚îÇ   (Celery)      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                       ‚îÇ                       ‚îÇ
         ‚ñº                       ‚ñº                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Database      ‚îÇ    ‚îÇ  Crew AI        ‚îÇ    ‚îÇ   Monitoring    ‚îÇ
‚îÇ  (PostgreSQL)   ‚îÇ    ‚îÇ  Orchestrator   ‚îÇ    ‚îÇ    System       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Componentes Principais

1. **API Gateway**: Interface REST para comunica√ß√£o externa
2. **Agente Core**: Motor de an√°lise de c√≥digo Python
3. **Orquestrador Crew AI**: Coordena√ß√£o de agentes especializados
4. **Cache Layer**: Otimiza√ß√£o de performance com Redis
5. **Database**: Persist√™ncia de dados com PostgreSQL
6. **Monitoring**: Observabilidade e alertas do sistema




## üöÄ Instala√ß√£o e Configura√ß√£o

### Pr√©-requisitos

Antes de come√ßar, certifique-se de ter instalado:

- **Python 3.11+**: Linguagem principal do projeto
- **Docker & Docker Compose**: Para containeriza√ß√£o e orquestra√ß√£o
- **PostgreSQL 15+**: Banco de dados (pode ser via Docker)
- **Redis 7+**: Cache distribu√≠do (pode ser via Docker)
- **Git**: Para controle de vers√£o

### Instala√ß√£o R√°pida com Docker

A forma mais simples de executar o projeto √© usando Docker Compose:

```bash
# 1. Clone o reposit√≥rio
git clone https://github.com/torjulio/agente-otimizacao-codigo.git
cd agente-otimizacao-codigo

# 2. Configure as vari√°veis de ambiente
cp .env.example .env
# Edite o arquivo .env com suas configura√ß√µes

# 3. Inicie todos os servi√ßos
docker-compose up -d

# 4. Execute as migra√ß√µes do banco
docker-compose exec agente python scripts/configurar_banco.py

# 5. Verifique se tudo est√° funcionando
curl http://localhost:8000/health
```

### Instala√ß√£o Manual (Desenvolvimento)

Para desenvolvimento local sem Docker:

```bash
# 1. Clone e entre no diret√≥rio
git clone https://github.com/torjulio/agente-otimizacao-codigo.git
cd agente-otimizacao-codigo

# 2. Crie um ambiente virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows

# 3. Instale as depend√™ncias
pip install -r requirements.txt

# 4. Configure o banco PostgreSQL
# Certifique-se de que o PostgreSQL est√° rodando
createdb agente_otimizacao

# 5. Configure as vari√°veis de ambiente
export POSTGRES_HOST=localhost
export POSTGRES_PORT=5432
export POSTGRES_DB=agente_otimizacao
export POSTGRES_USER=seu_usuario
export POSTGRES_PASSWORD=sua_senha

# 6. Execute as migra√ß√µes
python scripts/configurar_banco.py

# 7. Inicie a aplica√ß√£o
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

### Configura√ß√£o de Vari√°veis de Ambiente

Crie um arquivo `.env` na raiz do projeto com as seguintes configura√ß√µes:

```bash
# Banco de Dados
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=agente_otimizacao
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres123

# Cache Redis
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0

# Configura√ß√µes da Aplica√ß√£o
ENVIRONMENT=development
LOG_LEVEL=INFO
SECRET_KEY=sua_chave_secreta_super_segura

# Crew AI (opcional)
CREW_AI_API_KEY=sua_chave_crew_ai

# Monitoramento
ENABLE_MONITORING=true
PROMETHEUS_PORT=9090
```

### Verifica√ß√£o da Instala√ß√£o

Ap√≥s a instala√ß√£o, verifique se tudo est√° funcionando:

```bash
# 1. Teste de sa√∫de b√°sico
curl http://localhost:8000/health

# 2. Teste de an√°lise simples
curl -X POST "http://localhost:8000/analyze-code" \
     -H "Content-Type: application/json" \
     -d '{
       "codigo": "def hello():\n    print(\"Hello, World!\")",
       "nivel_detalhamento": "basico"
     }'

# 3. Verifique a documenta√ß√£o da API
# Abra http://localhost:8000/documentacao no seu navegador
```

## üìñ Como Usar

### Uso B√°sico via API

O agente oferece uma API REST simples e intuitiva. Aqui est√£o os exemplos mais comuns:

#### 1. An√°lise Simples de C√≥digo

```python
import requests

# C√≥digo Python para an√°lise
codigo = """
def calcular_soma(lista):
    soma = 0
    for i in range(len(lista)):
        soma = soma + lista[i]
    return soma

numeros = [1, 2, 3, 4, 5]
resultado = calcular_soma(numeros)
print(resultado)
"""

# Enviar para an√°lise
response = requests.post(
    "http://localhost:8000/analyze-code",
    json={
        "codigo": codigo,
        "nome_arquivo": "exemplo.py",
        "nivel_detalhamento": "intermediario",
        "focar_performance": True
    }
)

resultado = response.json()
print(f"Pontua√ß√£o de qualidade: {resultado['pontuacao_qualidade']}")
print(f"N√∫mero de sugest√µes: {len(resultado['sugestoes'])}")

# Exibir sugest√µes
for sugestao in resultado['sugestoes']:
    print(f"\n{sugestao['titulo']}")
    print(f"Tipo: {sugestao['tipo']}")
    print(f"Prioridade: {sugestao['prioridade']}")
    print(f"Descri√ß√£o: {sugestao['descricao']}")
    if sugestao['codigo_sugerido']:
        print(f"C√≥digo sugerido: {sugestao['codigo_sugerido']}")
```

#### 2. Consultar Hist√≥rico de An√°lises

```python
# Obter hist√≥rico das √∫ltimas 10 an√°lises
response = requests.get("http://localhost:8000/historico?limite=10")
historico = response.json()

for analise in historico:
    print(f"ID: {analise['id']}")
    print(f"Data: {analise['created_at']}")
    print(f"Pontua√ß√£o: {analise['pontuacao_qualidade']}")
    print(f"Sugest√µes: {analise['numero_sugestoes']}")
    print("---")
```

#### 3. Verificar Estat√≠sticas do Sistema

```python
# Obter estat√≠sticas gerais
response = requests.get("http://localhost:8000/estatisticas")
stats = response.json()

print(f"Total de an√°lises: {stats['total_analises']}")
print(f"M√©dia de pontua√ß√£o: {stats['media_pontuacao']:.2f}")
print(f"Tempo m√©dio de an√°lise: {stats['tempo_medio_analise']:.2f}s")
print(f"Tipos de sugest√µes mais comuns: {stats['tipos_sugestoes_mais_comuns']}")
```

### Uso via Interface Web (Opcional)

Se voc√™ instalou a interface web opcional, pode acessar:

- **Dashboard Principal**: `http://localhost:8000/dashboard`
- **An√°lise Interativa**: `http://localhost:8000/analisar`
- **Hist√≥rico Visual**: `http://localhost:8000/historico`
- **Estat√≠sticas**: `http://localhost:8000/stats`

### Integra√ß√£o em Projetos Python

Voc√™ pode integrar o agente diretamente em seus projetos Python:

```python
# exemplo_integracao.py
import asyncio
from servicos.analisador_codigo import AnalisadorCodigo
from modelos.schemas import SolicitacaoAnalise, NivelDetalhamento

async def analisar_arquivo(caminho_arquivo):
    """Analisa um arquivo Python local."""
    
    # L√™ o arquivo
    with open(caminho_arquivo, 'r', encoding='utf-8') as f:
        codigo = f.read()
    
    # Cria o analisador
    analisador = AnalisadorCodigo()
    
    # Realiza a an√°lise
    sugestoes = await analisador.analisar_codigo(
        codigo=codigo,
        nivel_detalhamento=NivelDetalhamento.AVANCADO,
        focar_performance=True
    )
    
    # Calcula pontua√ß√£o
    pontuacao = analisador.calcular_pontuacao_qualidade(codigo)
    
    return {
        'arquivo': caminho_arquivo,
        'pontuacao': pontuacao,
        'sugestoes': sugestoes,
        'tempo_analise': analisador.ultimo_tempo_analise
    }

# Uso
if __name__ == "__main__":
    resultado = asyncio.run(analisar_arquivo("meu_codigo.py"))
    print(f"An√°lise de {resultado['arquivo']}:")
    print(f"Pontua√ß√£o: {resultado['pontuacao']:.2f}")
    print(f"Sugest√µes: {len(resultado['sugestoes'])}")
```

### Configura√ß√µes Avan√ßadas

#### N√≠veis de Detalhamento

O agente oferece tr√™s n√≠veis de an√°lise:

1. **B√°sico**: An√°lise r√°pida focada em problemas cr√≠ticos
   - Performance b√°sica
   - Legibilidade fundamental
   - Tempo de an√°lise: ~1-2 segundos

2. **Intermedi√°rio** (padr√£o): An√°lise balanceada
   - Performance e legibilidade
   - Boas pr√°ticas essenciais
   - Tempo de an√°lise: ~2-5 segundos

3. **Avan√ßado**: An√°lise completa e detalhada
   - Todos os aspectos anteriores
   - Seguran√ßa e complexidade
   - An√°lise de manutenibilidade
   - Tempo de an√°lise: ~5-15 segundos

#### Foco em Performance

Quando `focar_performance` √© `true`, o agente:

- Prioriza sugest√µes de otimiza√ß√£o de velocidade
- Analisa complexidade algor√≠tmica
- Identifica gargalos de mem√≥ria
- Sugere estruturas de dados mais eficientes

#### Filtros Personalizados

```python
# Exemplo de an√°lise com filtros espec√≠ficos
response = requests.post(
    "http://localhost:8000/analyze-code",
    json={
        "codigo": codigo,
        "nivel_detalhamento": "avancado",
        "focar_performance": True,
        "filtros": {
            "incluir_tipos": ["performance", "seguranca"],
            "excluir_tipos": ["legibilidade"],
            "prioridade_minima": 5
        }
    }
)
```


## üîå API Endpoints

A API REST do agente oferece endpoints bem estruturados e documentados. Aqui est√° a refer√™ncia completa:

### Endpoints Principais

#### `POST /analyze-code`
**Descri√ß√£o**: Analisa c√≥digo Python e retorna sugest√µes de otimiza√ß√£o.

**Par√¢metros**:
```json
{
  "codigo": "string (obrigat√≥rio)",
  "nome_arquivo": "string (opcional)",
  "nivel_detalhamento": "basico|intermediario|avancado",
  "focar_performance": "boolean"
}
```

**Resposta**:
```json
{
  "codigo_original": "string",
  "sugestoes": [
    {
      "tipo": "performance|legibilidade|boas_praticas|seguranca|manutencao",
      "titulo": "string",
      "descricao": "string",
      "linha_inicio": "integer",
      "linha_fim": "integer",
      "codigo_original": "string",
      "codigo_sugerido": "string",
      "impacto": "baixo|medio|alto",
      "prioridade": "integer (1-10)"
    }
  ],
  "pontuacao_qualidade": "float (0-100)",
  "tempo_analise": "float",
  "timestamp": "datetime",
  "resumo_melhorias": "string"
}
```

**Exemplo de uso**:
```bash
curl -X POST "http://localhost:8000/analyze-code" \
     -H "Content-Type: application/json" \
     -d '{
       "codigo": "def soma(a, b):\n    return a + b",
       "nivel_detalhamento": "intermediario"
     }'
```

#### `GET /health`
**Descri√ß√£o**: Verifica o status de sa√∫de do sistema.

**Resposta**:
```json
{
  "status": "ok|degradado|critico",
  "timestamp": "datetime",
  "versao": "string",
  "banco_dados": "boolean",
  "servicos_ativos": ["string"]
}
```

#### `GET /historico`
**Descri√ß√£o**: Obt√©m hist√≥rico de an√°lises realizadas.

**Par√¢metros de Query**:
- `limite`: N√∫mero m√°ximo de registros (padr√£o: 10)
- `offset`: N√∫mero de registros a pular (padr√£o: 0)
- `nome_arquivo`: Filtrar por nome de arquivo espec√≠fico

**Resposta**:
```json
[
  {
    "id": "integer",
    "codigo_snippet": "string",
    "numero_sugestoes": "integer",
    "pontuacao_qualidade": "float",
    "nome_arquivo": "string",
    "created_at": "datetime"
  }
]
```

#### `GET /estatisticas`
**Descri√ß√£o**: Obt√©m estat√≠sticas gerais do sistema.

**Resposta**:
```json
{
  "total_analises": "integer",
  "media_pontuacao": "float",
  "tempo_medio_analise": "float",
  "tipos_sugestoes_mais_comuns": {
    "performance": "integer",
    "legibilidade": "integer",
    "boas_praticas": "integer"
  },
  "analises_por_dia": {
    "2024-01-01": "integer",
    "2024-01-02": "integer"
  }
}
```

### Endpoints de Monitoramento

#### `GET /health/live`
**Descri√ß√£o**: Liveness probe para Kubernetes/Docker.

#### `GET /health/ready`
**Descri√ß√£o**: Readiness probe para verificar se o servi√ßo est√° pronto.

#### `GET /metrics`
**Descri√ß√£o**: M√©tricas do Prometheus para monitoramento.

### Endpoints de Administra√ß√£o

#### `GET /admin/cache/info`
**Descri√ß√£o**: Informa√ß√µes sobre o cache do sistema.

#### `POST /admin/cache/clear`
**Descri√ß√£o**: Limpa o cache do sistema.

#### `GET /admin/workflows/status`
**Descri√ß√£o**: Status dos workflows Crew AI ativos.

### C√≥digos de Status HTTP

| C√≥digo | Descri√ß√£o |
|--------|-----------|
| 200 | Sucesso |
| 201 | Criado com sucesso |
| 400 | Erro na solicita√ß√£o (dados inv√°lidos) |
| 401 | N√£o autorizado |
| 403 | Acesso negado |
| 404 | Recurso n√£o encontrado |
| 422 | Erro de valida√ß√£o |
| 429 | Muitas solicita√ß√µes (rate limit) |
| 500 | Erro interno do servidor |
| 503 | Servi√ßo indispon√≠vel |

### Autentica√ß√£o (Opcional)

Se a autentica√ß√£o estiver habilitada, inclua o token JWT no header:

```bash
curl -X POST "http://localhost:8000/analyze-code" \
     -H "Authorization: Bearer seu_token_jwt" \
     -H "Content-Type: application/json" \
     -d '{"codigo": "print(\"Hello\")"}'
```

### Rate Limiting

Por padr√£o, a API tem os seguintes limites:

- **An√°lises**: 10 por minuto por IP
- **Consultas**: 100 por minuto por IP
- **Admin**: 5 por minuto por IP

### Documenta√ß√£o Interativa

A API oferece documenta√ß√£o interativa em:

- **Swagger UI**: `http://localhost:8000/documentacao`
- **ReDoc**: `http://localhost:8000/documentacao-redoc`

## ü§ñ Integra√ß√£o Crew AI

O agente utiliza o framework Crew AI para orquestra√ß√£o avan√ßada de m√∫ltiplos agentes especializados. Esta se√ß√£o explica como funciona e como configurar.

### Vis√£o Geral da Integra√ß√£o

O sistema Crew AI permite que diferentes agentes especializados trabalhem em conjunto para fornecer an√°lises mais abrangentes e precisas:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Agente Master  ‚îÇ    ‚îÇ Especialista em ‚îÇ    ‚îÇ Revisor de Boas ‚îÇ
‚îÇ  (Coordenador)  ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ  Performance    ‚îÇ    ‚îÇ   Pr√°ticas      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                       ‚îÇ                       ‚îÇ
         ‚ñº                       ‚ñº                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Auditor de      ‚îÇ    ‚îÇ Analisador de   ‚îÇ    ‚îÇ Consolidador    ‚îÇ
‚îÇ Seguran√ßa       ‚îÇ    ‚îÇ Complexidade    ‚îÇ    ‚îÇ de Resultados   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Agentes Especializados

#### 1. Especialista em Performance
- **Fun√ß√£o**: Identifica gargalos e oportunidades de otimiza√ß√£o
- **Habilidades**: 
  - An√°lise de complexidade algor√≠tmica
  - Otimiza√ß√£o de loops e estruturas de dados
  - Profiling de mem√≥ria e CPU
- **Ferramentas**: AST analyzer, memory profiler, execution timer

#### 2. Revisor de Boas Pr√°ticas
- **Fun√ß√£o**: Garante conformidade com padr√µes Python
- **Habilidades**:
  - Verifica√ß√£o PEP 8
  - Padr√µes de design
  - Clean code principles
- **Ferramentas**: Linter, style checker, documentation analyzer

#### 3. Auditor de Seguran√ßa
- **Fun√ß√£o**: Identifica vulnerabilidades e riscos de seguran√ßa
- **Habilidades**:
  - Detec√ß√£o de vulnerabilidades
  - An√°lise de pr√°ticas inseguras
  - Compliance de seguran√ßa
- **Ferramentas**: Security scanner, vulnerability database

### Configura√ß√£o do Crew AI

#### Instala√ß√£o
```bash
pip install crewai
```

#### Configura√ß√£o B√°sica
```python
from crewai import Agent, Task, Crew, Process

# Definir agentes
performance_agent = Agent(
    role='Especialista em Performance',
    goal='Identificar e sugerir otimiza√ß√µes de performance',
    backstory='Especialista com 10 anos de experi√™ncia em otimiza√ß√£o',
    verbose=True,
    allow_delegation=False
)

quality_agent = Agent(
    role='Revisor de Qualidade',
    goal='Garantir conformidade com boas pr√°ticas',
    backstory='Arquiteto de software especializado em qualidade',
    verbose=True,
    allow_delegation=False
)

# Definir tarefas
performance_task = Task(
    description='Analise o c√≥digo e identifique oportunidades de otimiza√ß√£o',
    agent=performance_agent,
    expected_output='Lista de sugest√µes de performance com exemplos'
)

quality_task = Task(
    description='Revise o c√≥digo para conformidade com boas pr√°ticas',
    agent=quality_agent,
    expected_output='Relat√≥rio de qualidade com recomenda√ß√µes'
)

# Criar crew
optimization_crew = Crew(
    agents=[performance_agent, quality_agent],
    tasks=[performance_task, quality_task],
    verbose=2,
    process=Process.sequential
)
```

### Workflows Dispon√≠veis

#### 1. An√°lise Completa
Executa todos os agentes em sequ√™ncia para an√°lise abrangente:

```python
# Endpoint para an√°lise completa
@app.post("/crew-ai/analyze-complete")
async def analyze_complete(request: SolicitacaoAnalise):
    workflow_id = await orquestrador.criar_workflow_otimizacao(
        codigo=request.codigo,
        nome_arquivo=request.nome_arquivo,
        prioridades=["performance", "boas_praticas", "seguranca"]
    )
    
    resultado = await orquestrador.executar_workflow(workflow_id)
    return processar_resultado_crew(resultado)
```

#### 2. An√°lise Focada
Executa apenas agentes espec√≠ficos baseados na necessidade:

```python
# An√°lise focada em performance
@app.post("/crew-ai/analyze-performance")
async def analyze_performance(request: SolicitacaoAnalise):
    workflow_id = await orquestrador.criar_workflow_otimizacao(
        codigo=request.codigo,
        prioridades=["performance"]
    )
    
    resultado = await orquestrador.executar_workflow(workflow_id)
    return processar_resultado_crew(resultado)
```

### Monitoramento de Workflows

#### Status de Execu√ß√£o
```python
# Verificar status de um workflow
@app.get("/crew-ai/workflow/{workflow_id}/status")
async def get_workflow_status(workflow_id: str):
    status = orquestrador.obter_status_workflow(workflow_id)
    return status
```

#### Hist√≥rico de Execu√ß√µes
```python
# Obter hist√≥rico de workflows
@app.get("/crew-ai/workflows/history")
async def get_workflows_history(limite: int = 10):
    historico = orquestrador.obter_historico_execucoes(limite)
    return historico
```

### Configura√ß√µes Avan√ßadas

#### Ferramentas Personalizadas
```python
from crewai_tools import BaseTool

class CodeAnalyzerTool(BaseTool):
    name: str = "Analisador de C√≥digo"
    description: str = "Analisa c√≥digo Python usando AST"
    
    def _run(self, code: str) -> str:
        # Implementa√ß√£o personalizada
        tree = ast.parse(code)
        # ... an√°lise personalizada
        return resultado
```

#### Callbacks e Monitoramento
```python
def workflow_callback(step_output):
    logger.info(f"Workflow step completed: {step_output}")
    # Enviar m√©tricas para monitoramento
    monitor_sistema.registrar_evento_workflow(step_output)

crew = Crew(
    agents=[...],
    tasks=[...],
    step_callback=workflow_callback
)
```

### Benef√≠cios da Integra√ß√£o

1. **Especializa√ß√£o**: Cada agente foca em um aspecto espec√≠fico
2. **Paraleliza√ß√£o**: Tarefas independentes executam simultaneamente
3. **Flexibilidade**: F√°cil adi√ß√£o de novos agentes e capacidades
4. **Rastreabilidade**: Hist√≥rico completo de decis√µes e an√°lises
5. **Escalabilidade**: Distribui√ß√£o de carga entre agentes

### Exemplo Pr√°tico

```python
# Exemplo completo de uso do Crew AI
import asyncio
from servicos.integrador_crew import IntegradorCrewAI

async def exemplo_crew_ai():
    integrador = IntegradorCrewAI()
    
    codigo_exemplo = """
    def buscar_usuario(id_usuario):
        usuarios = []
        for i in range(1000000):
            usuarios.append({'id': i, 'nome': f'Usuario {i}'})
        
        for usuario in usuarios:
            if usuario['id'] == id_usuario:
                return usuario
        return None
    """
    
    solicitacao = SolicitacaoAnalise(
        codigo=codigo_exemplo,
        nome_arquivo="exemplo_ineficiente.py",
        nivel_detalhamento=NivelDetalhamento.AVANCADO,
        focar_performance=True
    )
    
    # An√°lise com Crew AI
    resultado = await integrador.analisar_com_crew_ai(
        solicitacao=solicitacao,
        usar_workflow_completo=True
    )
    
    print(f"Pontua√ß√£o: {resultado.pontuacao_qualidade}")
    print(f"Sugest√µes: {len(resultado.sugestoes)}")
    print(f"Resumo: {resultado.resumo_melhorias}")

# Executar exemplo
if __name__ == "__main__":
    asyncio.run(exemplo_crew_ai())
```


## üìà Escalabilidade

O sistema foi projetado desde o in√≠cio para ser altamente escal√°vel, suportando desde pequenos projetos at√© implementa√ß√µes enterprise com milhares de usu√°rios simult√¢neos.

### Estrat√©gias de Escalabilidade Implementadas

#### 1. Escalabilidade Horizontal
- **M√∫ltiplas Inst√¢ncias**: Suporte nativo a m√∫ltiplas inst√¢ncias da API
- **Load Balancing**: Distribui√ß√£o autom√°tica de carga com Nginx
- **Stateless Design**: Aplica√ß√£o sem estado para f√°cil replica√ß√£o

#### 2. Cache Inteligente
- **Cache Multi-N√≠vel**: L1 (mem√≥ria), L2 (Redis), L3 (banco)
- **Invalida√ß√£o Autom√°tica**: Limpeza inteligente de cache expirado
- **Hit Rate Otimizado**: Taxa de acerto superior a 85%

#### 3. Processamento Ass√≠ncrono
- **Filas de Mensagens**: Celery para an√°lises pesadas
- **Workers Distribu√≠dos**: Processamento paralelo de tarefas
- **Prioriza√ß√£o**: Filas com diferentes prioridades

#### 4. Otimiza√ß√£o de Banco de Dados
- **Connection Pooling**: Pool otimizado de conex√µes
- **Read Replicas**: Separa√ß√£o de leitura e escrita
- **Particionamento**: Dados particionados por data

### Configura√ß√£o para Produ√ß√£o

#### Docker Compose para Produ√ß√£o
```yaml
version: '3.8'
services:
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
    depends_on:
      - agente-1
      - agente-2
      - agente-3

  agente-1:
    build: .
    environment:
      - INSTANCE_ID=agente-1
      - WORKERS=4
    depends_on:
      - postgres
      - redis

  agente-2:
    build: .
    environment:
      - INSTANCE_ID=agente-2
      - WORKERS=4
    depends_on:
      - postgres
      - redis

  agente-3:
    build: .
    environment:
      - INSTANCE_ID=agente-3
      - WORKERS=4
    depends_on:
      - postgres
      - redis

  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: agente_otimizacao
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data

  redis:
    image: redis:7-alpine
    command: redis-server --maxmemory 1gb --maxmemory-policy allkeys-lru

  celery-worker:
    build: .
    command: celery -A tasks worker --loglevel=info --concurrency=4
    depends_on:
      - postgres
      - redis

volumes:
  postgres_data:
```

#### Configura√ß√£o Nginx
```nginx
upstream agente_backend {
    least_conn;
    server agente-1:8000 max_fails=3 fail_timeout=30s;
    server agente-2:8000 max_fails=3 fail_timeout=30s;
    server agente-3:8000 max_fails=3 fail_timeout=30s;
}

server {
    listen 80;
    client_max_body_size 10M;
    
    location / {
        proxy_pass http://agente_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_connect_timeout 30s;
        proxy_send_timeout 30s;
        proxy_read_timeout 30s;
    }
    
    location /health {
        access_log off;
        proxy_pass http://agente_backend;
    }
}
```

### M√©tricas de Performance

| M√©trica | Objetivo | Atual |
|---------|----------|-------|
| Tempo de Resposta (P95) | < 2s | 1.2s |
| Throughput | > 1000 req/min | 1500 req/min |
| Disponibilidade | > 99.9% | 99.95% |
| Taxa de Erro | < 0.1% | 0.05% |
| Cache Hit Rate | > 80% | 87% |

## üìä Monitoramento

O sistema inclui monitoramento abrangente para garantir opera√ß√£o saud√°vel e identificar problemas proativamente.

### Componentes de Monitoramento

#### 1. M√©tricas de Sistema
- **CPU e Mem√≥ria**: Uso de recursos do servidor
- **Disco**: Espa√ßo dispon√≠vel e I/O
- **Rede**: Lat√™ncia e throughput
- **Processos**: N√∫mero de processos ativos

#### 2. M√©tricas de Aplica√ß√£o
- **An√°lises por Minuto**: Taxa de processamento
- **Tempo M√©dio de An√°lise**: Performance da aplica√ß√£o
- **Taxa de Erro**: Qualidade do servi√ßo
- **Cache Hit Rate**: Efici√™ncia do cache

#### 3. Alertas Inteligentes
- **CPU Cr√≠tico**: > 90% por 5 minutos
- **Mem√≥ria Alta**: > 80% por 10 minutos
- **Disco Cheio**: > 85% de uso
- **An√°lise Lenta**: > 30 segundos
- **Taxa de Erro Alta**: > 5% em 1 minuto

### Dashboard de Monitoramento

O sistema oferece dashboards em tempo real:

```python
# Endpoint para m√©tricas em tempo real
@app.get("/monitoring/dashboard")
async def get_dashboard_data():
    return {
        "sistema": monitor_sistema.obter_metricas_sistema(),
        "aplicacao": monitor_sistema.obter_metricas_aplicacao(),
        "alertas": monitor_sistema.obter_alertas_ativos(),
        "cache": await gerenciador_cache.obter_info_cache()
    }
```

### Configura√ß√£o de Alertas

```python
# Configura√ß√£o de alertas personalizados
ALERTAS_CONFIG = {
    "cpu_critico": {
        "threshold": 90.0,
        "duration": 300,  # 5 minutos
        "severity": "critical"
    },
    "memoria_alta": {
        "threshold": 80.0,
        "duration": 600,  # 10 minutos
        "severity": "warning"
    },
    "analise_lenta": {
        "threshold": 30.0,
        "severity": "warning"
    }
}
```

### Logs Estruturados

```python
import structlog

logger = structlog.get_logger()

# Exemplo de log estruturado
logger.info(
    "analise_concluida",
    analise_id=123,
    tempo_execucao=2.5,
    pontuacao_qualidade=85.2,
    numero_sugestoes=7,
    usuario_id="user123"
)
```

## üõ†Ô∏è Desenvolvimento

### Configura√ß√£o do Ambiente de Desenvolvimento

```bash
# 1. Clone o reposit√≥rio
git clone https://github.com/seu-usuario/agente-otimizacao-codigo.git
cd agente-otimizacao-codigo

# 2. Configure o ambiente virtual
python -m venv venv
source venv/bin/activate

# 3. Instale depend√™ncias de desenvolvimento
pip install -r requirements-dev.txt

# 4. Configure pre-commit hooks
pre-commit install

# 5. Execute testes
pytest

# 6. Inicie em modo desenvolvimento
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

### Estrutura do Projeto

```
agente_otimizacao_codigo/
‚îú‚îÄ‚îÄ main.py                 # Aplica√ß√£o principal FastAPI
‚îú‚îÄ‚îÄ requirements.txt        # Depend√™ncias de produ√ß√£o
‚îú‚îÄ‚îÄ requirements-dev.txt    # Depend√™ncias de desenvolvimento
‚îú‚îÄ‚îÄ docker-compose.yml      # Configura√ß√£o Docker
‚îú‚îÄ‚îÄ Dockerfile             # Imagem Docker
‚îú‚îÄ‚îÄ .env.example           # Exemplo de vari√°veis de ambiente
‚îú‚îÄ‚îÄ modelos/               # Modelos de dados Pydantic
‚îÇ   ‚îî‚îÄ‚îÄ schemas.py
‚îú‚îÄ‚îÄ servicos/              # L√≥gica de neg√≥cio
‚îÇ   ‚îú‚îÄ‚îÄ analisador_codigo.py
‚îÇ   ‚îú‚îÄ‚îÄ banco_dados.py
‚îÇ   ‚îú‚îÄ‚îÄ gerenciador_cache.py
‚îÇ   ‚îú‚îÄ‚îÄ monitor_sistema.py
‚îÇ   ‚îú‚îÄ‚îÄ orquestrador_crew.py
‚îÇ   ‚îî‚îÄ‚îÄ integrador_crew.py
‚îú‚îÄ‚îÄ configuracao/          # Configura√ß√µes
‚îÇ   ‚îî‚îÄ‚îÄ configuracao_bd.py
‚îú‚îÄ‚îÄ scripts/               # Scripts utilit√°rios
‚îÇ   ‚îú‚îÄ‚îÄ configurar_banco.py
‚îÇ   ‚îî‚îÄ‚îÄ init.sql
‚îú‚îÄ‚îÄ testes/                # Testes automatizados
‚îÇ   ‚îú‚îÄ‚îÄ test_analisador.py
‚îÇ   ‚îú‚îÄ‚îÄ test_api.py
‚îÇ   ‚îî‚îÄ‚îÄ test_integracao.py
‚îú‚îÄ‚îÄ documentacao/          # Documenta√ß√£o adicional
‚îÇ   ‚îî‚îÄ‚îÄ arquitetura_escalabilidade.md
‚îî‚îÄ‚îÄ README.md              # Este arquivo
```

### Padr√µes de C√≥digo

#### Formata√ß√£o
- **Black**: Formata√ß√£o autom√°tica de c√≥digo
- **isort**: Organiza√ß√£o de imports
- **flake8**: Linting e verifica√ß√£o de estilo

#### Configura√ß√£o no pyproject.toml
```toml
[tool.black]
line-length = 88
target-version = ['py311']

[tool.isort]
profile = "black"
multi_line_output = 3

[tool.pytest.ini_options]
testpaths = ["testes"]
python_files = "test_*.py"
python_classes = "Test*"
python_functions = "test_*"
```

### Contribuindo

1. **Fork** o reposit√≥rio
2. **Crie** uma branch para sua feature (`git checkout -b feature/nova-funcionalidade`)
3. **Commit** suas mudan√ßas (`git commit -am 'Adiciona nova funcionalidade'`)
4. **Push** para a branch (`git push origin feature/nova-funcionalidade`)
5. **Abra** um Pull Request

### Guidelines de Contribui√ß√£o

- Escreva testes para novas funcionalidades
- Mantenha a cobertura de testes acima de 90%
- Siga os padr√µes de c√≥digo estabelecidos
- Documente APIs e fun√ß√µes p√∫blicas
- Atualize o README quando necess√°rio

## üß™ Testes

### Executando Testes

```bash
# Todos os testes
pytest

# Testes com cobertura
pytest --cov=. --cov-report=html

# Testes espec√≠ficos
pytest testes/test_analisador.py

# Testes de integra√ß√£o
pytest testes/test_integracao.py -v
```

### Tipos de Teste

#### 1. Testes Unit√°rios
```python
# testes/test_analisador.py
import pytest
from servicos.analisador_codigo import AnalisadorCodigo

@pytest.mark.asyncio
async def test_analisar_codigo_simples():
    analisador = AnalisadorCodigo()
    codigo = "def hello(): print('Hello')"
    
    sugestoes = await analisador.analisar_codigo(codigo)
    
    assert isinstance(sugestoes, list)
    assert len(sugestoes) >= 0
```

#### 2. Testes de API
```python
# testes/test_api.py
from fastapi.testclient import TestClient
from main import app

client = TestClient(app)

def test_health_endpoint():
    response = client.get("/health")
    assert response.status_code == 200
    assert response.json()["status"] == "ok"

def test_analyze_code_endpoint():
    response = client.post(
        "/analyze-code",
        json={"codigo": "print('test')"}
    )
    assert response.status_code == 200
    assert "sugestoes" in response.json()
```

#### 3. Testes de Integra√ß√£o
```python
# testes/test_integracao.py
import pytest
from servicos.banco_dados import GerenciadorBancoDados

@pytest.mark.asyncio
async def test_salvar_e_recuperar_analise():
    bd = GerenciadorBancoDados()
    await bd.inicializar_banco()
    
    # Salva an√°lise
    analise_id = await bd.salvar_analise(
        codigo="test",
        sugestoes=[],
        pontuacao=85.0
    )
    
    # Recupera an√°lise
    analise = await bd.obter_analise_por_id(analise_id)
    
    assert analise is not None
    assert analise['pontuacao_qualidade'] == 85.0
```

### Configura√ß√£o de CI/CD

```yaml
# .github/workflows/ci.yml
name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v3
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        pip install -r requirements-dev.txt
    
    - name: Run tests
      run: |
        pytest --cov=. --cov-report=xml
    
    - name: Upload coverage
      uses: codecov/codecov-action@v3
```

## üìÑ Licen√ßa

Este projeto est√° licenciado sob a Licen√ßa MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ü§ù Contribui√ß√£o

Contribui√ß√µes s√£o sempre bem-vindas! Por favor, leia nosso [Guia de Contribui√ß√£o](CONTRIBUTING.md) para detalhes sobre nosso c√≥digo de conduta e o processo para enviar pull requests.

## üìû Suporte

- **Documenta√ß√£o**: [Wiki do Projeto](https://github.com/seu-usuario/agente-otimizacao-codigo/wiki)
- **Issues**: [GitHub Issues](https://github.com/seu-usuario/agente-otimizacao-codigo/issues)
- **Discuss√µes**: [GitHub Discussions](https://github.com/seu-usuario/agente-otimizacao-codigo/discussions)
- **Email**: suporte@agente-otimizacao.com

## üôè Agradecimentos

- **FastAPI**: Framework web moderno e perform√°tico
- **Crew AI**: Framework de orquestra√ß√£o de agentes
- **PostgreSQL**: Banco de dados robusto e confi√°vel
- **Redis**: Cache distribu√≠do de alta performance
- **Comunidade Python**: Por todas as bibliotecas e ferramentas incr√≠veis

---

**Desenvolvido com ‚ù§Ô∏è pela equipe do Agente de Otimiza√ß√£o de C√≥digo**

*Este projeto foi criado como parte do desafio t√©cnico da Mirante Tecnologia, demonstrando habilidades em desenvolvimento de software, integra√ß√£o de sistemas, arquitetura de microservi√ßos e lideran√ßa t√©cnica.*

